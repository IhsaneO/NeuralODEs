## IMPORT LIBRARIES

import os

import argparse

import logging

import time

import numpy as np

import torch

import torch.nn as nn

from torch.utils.data import DataLoader

import torchvision.datasets as datasets

import torchvision.transforms as transforms # Transform and Augment an image

## GET THE ARGUMENTS

parser = argparse.ArgumentParser()

parser.add_argument('--network', type=str, choices=['resnet', 'odenet'], default='odenet') # Model to use

parser.add_argument('--tol', type=float, default=1e-3) # Tolerance

parser.add_argument('--adjoint', type=eval, default=False, choices=[True, False]) # Adjoint sensitivity method - Computes gradients by solving an augmented ODE backward in time

parser.add_argument('--downsampling-method', type=str, default='conv', choices=['conv', 'res']) # Downsampling method for the input

parser.add_argument('--nepochs', type=int, default=160) # Number of epochs

parser.add_argument('--data_aug', type=eval, default=True, choices=[True, False]) # Augment the dataset

parser.add_argument('--lr', type=float, default=0.1) # Learning Rate

parser.add_argument('--batch_size', type=int, default=128) # Training Batch Size

parser.add_argument('--test_batch_size', type=int, default=1000) # Test Batch Size

parser.add_argument('--save', type=str, default='./experiment1') # Save the results

parser.add_argument('--debug', action='store_true')

parser.add_argument('--gpu', type=int, default=0) # Use of the GPU or not

args = parser.parse_args()

## DEFINE IF WE'RE USING ADJOINTS OR NOT

if args.adjoint:
    
    from torchdiffeq import odeint_adjoint as odeint

else:
    
    from torchdiffeq import odeint

## DEFINE THE DIFFERENT LAYERS TO BE USED LATER ON

# 3x3 Convolution with padding
def conv3x3(in_planes, out_planes, stride=1):

    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)

# 1x1 Convolution without padding
def conv1x1(in_planes, out_planes, stride=1):

    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)

# Group Normalisation over a batch of inputs
def norm(dim):
    return nn.GroupNorm(min(32, dim), dim)


## RESNET NODE TO BE USED

class ResBlock(nn.Module):
    expansion = 1

    def __init__(self, inplanes, planes, stride=1, downsample=None):
        
        super(ResBlock, self).__init__()
        
        self.norm1 = norm(inplanes) # Normalise
        
        self.relu = nn.ReLU(inplace=True)
        
        self.downsample = downsample # Choice for downsampling
        
        self.conv1 = conv3x3(inplanes, planes, stride) # 3x3 convolution
        
        self.norm2 = norm(planes)
        
        self.conv2 = conv3x3(planes, planes)

    def forward(self, x):
        
        shortcut = x

        out = self.relu(self.norm1(x))

        if self.downsample is not None:
        
            shortcut = self.downsample(out)

        out = self.conv1(out)
        
        out = self.norm2(out)
        
        out = self.relu(out)
        
        out = self.conv2(out)

        return out + shortcut


## 2D CONVOLUTIONAL LAYER 

class ConcatConv2d(nn.Module):

    def __init__(self, dim_in, dim_out, ksize=3, stride=1, padding=0, dilation=1, groups=1, bias=True, transpose=False):
        
        super(ConcatConv2d, self).__init__()
        
        module = nn.ConvTranspose2d if transpose else nn.Conv2d # If use 2D convolutional Block with or without transpose
        
        self._layer = module(
            dim_in + 1, dim_out, kernel_size=ksize, stride=stride, padding=padding, dilation=dilation, groups=groups,
            bias=bias
        )

    def forward(self, t, x):
        
        tt = torch.ones_like(x[:, :1, :, :]) * t
        
        ttx = torch.cat([tt, x], 1)
        
        return self._layer(ttx)


## ODE FUNCTION TO SOLVE - ODE RELATING AN IMAGE TO A NUMBER

class ODEfunc(nn.Module):

    def __init__(self, dim):
        
        super(ODEfunc, self).__init__()
        
        self.norm1 = norm(dim) # Normalise Layer
        
        self.relu = nn.ReLU(inplace=True)
        
        self.conv1 = ConcatConv2d(dim, dim, 3, 1, 1) # Convolutional Layer
        
        self.norm2 = norm(dim)
        
        self.conv2 = ConcatConv2d(dim, dim, 3, 1, 1)
        
        self.norm3 = norm(dim)
        
        self.nfe = 0 # Initialise the number of function evaluation to 0
        
    def forward(self, t, x):
        
        self.nfe += 1 # Add +1 for each new function evaluation
        
        out = self.norm1(x)
        
        out = self.relu(out)
        
        out = self.conv1(t, out)
        
        out = self.norm2(out)
        
        out = self.relu(out)
        
        out = self.conv2(t, out)
        
        out = self.norm3(out)
        
        return out


## ODE NODE USED IN THE MODEL

class ODEBlock(nn.Module):

    def __init__(self, odefunc):
        
        super(ODEBlock, self).__init__()
        
        self.odefunc = odefunc
        
        self.integration_time = torch.tensor([0, 1]).float()

    def forward(self, x):
        
        self.integration_time = self.integration_time.type_as(x)
        
        out = odeint(self.odefunc, x, self.integration_time, rtol=args.tol, atol=args.tol)
        
        return out[1]

    @property
    def nfe(self):
        
        return self.odefunc.nfe # Get the number of function evaluation

    @nfe.setter
    def nfe(self, value):
        
        self.odefunc.nfe = value


## FLATTENING LAYER

class Flatten(nn.Module):

    def __init__(self):
        
        super(Flatten, self).__init__()

    def forward(self, x):
        
        shape = torch.prod(torch.tensor(x.shape[1:])).item()
        
        return x.view(-1, shape)


## COMPUTE AND STORE THE AVERAGE AND CURRENT VALUE

class RunningAverageMeter(object):

    def __init__(self, momentum=0.99):
        
        self.momentum = momentum
        
        self.reset()

    def reset(self):
        
        self.val = None
        
        self.avg = 0

    def update(self, val):
        
        if self.val is None:
        
            self.avg = val
        
        else:
        
            self.avg = self.avg * self.momentum + val * (1 - self.momentum) # Compute the new average value with the new value
        
        self.val = val


## GET THE TRAINING? EVALUATION AND TEST DATASETS

def get_mnist_loaders(data_aug=False, batch_size=128, test_batch_size=1000, perc=1.0):
    
    # If Data Augmentation is set to True
    if data_aug:
        
        # Set the training transformation to random cropping and padding the images constantly + Set it as a tensor
        transform_train = transforms.Compose([
            transforms.RandomCrop(28, padding=4),
            transforms.ToTensor(),
        ])
    
    else:
        
        # Set the training transformation as only setting the as a tensor
        transform_train = transforms.Compose([
            transforms.ToTensor(),
        ])

    # Set the testing transformation as only setting the data as a tensor
    transform_test = transforms.Compose([
        transforms.ToTensor(),
    ])

    # Load the training set of a certain batch_size from the MNSIT set, applying the training transformation, set it as trainable and shuffling
    train_loader = DataLoader(
        datasets.MNIST(root='.data/mnist', train=True, download=True, transform=transform_train), batch_size=batch_size,
        shuffle=True, num_workers=2, drop_last=True
    )
    
    # Load the evaluation set of a certain batch_size from the MNSIT set, applying the test transformation and set it as trainable
    train_eval_loader = DataLoader(
        datasets.MNIST(root='.data/mnist', train=True, download=True, transform=transform_test),
        batch_size=test_batch_size, shuffle=False, num_workers=2, drop_last=True
    )

    # Load the test set of a certain batch_size from the MNSIT set, applying the test transformation as set it to non trainable
    test_loader = DataLoader(
        datasets.MNIST(root='.data/mnist', train=False, download=True, transform=transform_test),
        batch_size=test_batch_size, shuffle=False, num_workers=2, drop_last=True
    )

    return train_loader, test_loader, train_eval_loader


## CREATE AN INFINITE LOOP TO GENERATE TRAINING SETS

def inf_generator(iterable):
    """Allows training with DataLoaders in a single infinite loop:
        for i, (x, y) in enumerate(inf_generator(train_loader)):
    """
    
    iterator = iterable.__iter__()
    
    while True:
    
        try:
        
            yield iterator.__next__()
        
        except StopIteration:
        
            iterator = iterable.__iter__()


## IMPLEMENT A DECAYING LEARNING RATE - LEARN LESS FROM THE LOSS AS WE GET TO LONGER TRAINING TIME

def learning_rate_with_decay(batch_size, batch_denom, batches_per_epoch, boundary_epochs, decay_rates):
    
    initial_learning_rate = args.lr * batch_size / batch_denom

    boundaries = [int(batches_per_epoch * epoch) for epoch in boundary_epochs] # Set when the learning rate is changing
    
    vals = [initial_learning_rate * decay for decay in decay_rates] # Set the learning rates at each changing point

    def learning_rate_fn(itr):
    
        lt = [itr < b for b in boundaries] + [True]
        
        i = np.argmax(lt)
        
        return vals[i]

    return learning_rate_fn

## RETURN THE ARRAY WHERE TRUE IS THE DIGIT IN X

def one_hot(x, K):
    return np.array(x[:, None] == np.arange(K)[None, :], dtype=int)


## COMPUTE THE ACCURACY

def accuracy(model, dataset_loader):
    
    total_correct = 0
    
    for x, y in dataset_loader: # X = image, Y = number
    
        x = x.to(device)
        
        y = one_hot(np.array(y.numpy()), 10) # Get which number it is

        target_class = np.argmax(y, axis=1) # Return the index of the number represented in this image
        
        predicted_class = np.argmax(model(x).cpu().detach().numpy(), axis=1) # Get the predicted number
        
        total_correct += np.sum(predicted_class == target_class) # Add +1 if it got the correct number
    
    return total_correct / len(dataset_loader.dataset)


## GET THE NUMBER OF PARAMETERS

def count_parameters(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)


## CREATE A DIRECTORIY IF IT DOESN'T EXIST

def makedirs(dirname):
    if not os.path.exists(dirname):
        os.makedirs(dirname)


## CREATE A LOGGER

def get_logger(logpath, filepath, package_files=[], displaying=True, saving=True, debug=False):
    
    logger = logging.getLogger()
    
    if debug: # If Debug is set to True
        
        level = logging.DEBUG # Save info about debugging
    
    else:
        
        level = logging.INFO # Save general information
    
    logger.setLevel(level)
    
    if saving:
        
        info_file_handler = logging.FileHandler(logpath, mode="a") # Set the saving path for the logging file
        
        info_file_handler.setLevel(level) # Set the level of logging
        
        logger.addHandler(info_file_handler) # Add the saving into the Logger
    
    if displaying:
        
        console_handler = logging.StreamHandler() # Disply the logs
        
        console_handler.setLevel(level)
        
        logger.addHandler(console_handler) # Add the displaying into the Logger
    
    logger.info(filepath)
    
    with open(filepath, "r") as f:
    
        logger.info(f.read())

    for f in package_files:
        
        logger.info(f)
        
        with open(f, "r") as package_f:
        
            logger.info(package_f.read())

    return logger


## MAIN CODE

if __name__ == '__main__':

    makedirs(args.save) # Create the folder to save the results
    
    logger = get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__)) # Create the logger file
    
    logger.info(args) # Add in the log the info about the arguments used

    device = torch.device('cuda:' + str(args.gpu) if torch.cuda.is_available() else 'cpu') # Set the training to CPU or GPU

    is_odenet = args.network == 'odenet' # Use of the ODE Network or not

        # If downsampling was set to True
    if args.downsampling_method == 'conv': # If downsampling is convolution
        
        downsampling_layers = [
            nn.Conv2d(1, 64, 3, 1),
            norm(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 4, 2, 1),
            norm(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 4, 2, 1),
        ]
    
    elif args.downsampling_method == 'res': # If downsampling is residual
        
        downsampling_layers = [
            nn.Conv2d(1, 64, 3, 1),
            ResBlock(64, 64, stride=2, downsample=conv1x1(64, 64, 2)),
            ResBlock(64, 64, stride=2, downsample=conv1x1(64, 64, 2)),
        ]

    feature_layers = [ODEBlock(ODEfunc(64))] if is_odenet else [ResBlock(64, 64) for _ in range(6)] # Layer of the training blocks - Residual or ODE
    
    fc_layers = [norm(64), nn.ReLU(inplace=True), nn.AdaptiveAvgPool2d((1, 1)), Flatten(), nn.Linear(64, 10)] # Fully connected layer linking the trainign blocks to the final Guess of the number in the image

    model = nn.Sequential(*downsampling_layers, *feature_layers, *fc_layers).to(device) # Define the model to train

    logger.info(model) # Add in the log the info about the model
    
    logger.info('Number of parameters: {}'.format(count_parameters(model))) # Add in the log the number of trainable parameters in the model

    criterion = nn.CrossEntropyLoss().to(device) # Cross Entropy loss for this classification task

    # Get the training, evaluation and test datasets
    train_loader, test_loader, train_eval_loader = get_mnist_loaders(
        args.data_aug, args.batch_size, args.test_batch_size
    )

    data_gen = inf_generator(train_loader) # Create an infinite set of training sets
    
    batches_per_epoch = len(train_loader) # Get the number of batches

    # Define the Learning rate function, which varies with the epoch where we're at
    lr_fn = learning_rate_with_decay(
        args.batch_size, batch_denom=128, batches_per_epoch=batches_per_epoch, boundary_epochs=[60, 100, 140],
        decay_rates=[1, 0.1, 0.01, 0.001]
    )

    optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, momentum=0.9) # Stochastic Gradient Descent as Optimiser

    best_acc = 0 # Initialise the best accuracy
    
    batch_time_meter = RunningAverageMeter() # Get the average time used to run a batch
    
    f_nfe_meter = RunningAverageMeter() # Get the average number of forward function evaluation
    
    b_nfe_meter = RunningAverageMeter() # Get the average number of backward function evaluation
    
    end = time.time() # Initialise to the current time

    for itr in range(args.nepochs * batches_per_epoch): # Going every single batch for each epoch

        for param_group in optimizer.param_groups: 
    
            param_group['lr'] = lr_fn(itr) # Get the learning rate

        optimizer.zero_grad() # Initialise the gradients to 0
        
        x, y = data_gen.__next__() # Generate a new training set
        
        x = x.to(device)
        
        y = y.to(device)
        
        logits = model(x) # Get the predictions from the model
        
        loss = criterion(logits, y) # Compute the loss associated

        if is_odenet: 
        
            nfe_forward = feature_layers[0].nfe # Get the number of function evaluations
            
            feature_layers[0].nfe = 0 # Reinitialise the counter of NFE to 0

        loss.backward() # Backpropagate
        
        optimizer.step() # Optimise the ODE function weights

        if is_odenet: 
            
            nfe_backward = feature_layers[0].nfe # Get the number of function evaluations
            
            feature_layers[0].nfe = 0 # Reinitialise the counter of NFE to 0

        batch_time_meter.update(time.time() - end) # Update the average time taken to run a batch 
        
        if is_odenet:
                
                # Update the average number of NFE forward and backward
            f_nfe_meter.update(nfe_forward)
            
            b_nfe_meter.update(nfe_backward)
        
        end = time.time() # Initialise the current time

        if itr % batches_per_epoch == 0: # After each epoch
        
            with torch.no_grad(): # Without computing gradients
            
                train_acc = accuracy(model, train_eval_loader) # Evaluate the training accuracy
                
                val_acc = accuracy(model, test_loader) # Evaluate the test accuracy
                
                if val_acc > best_acc: # If the test accuracy is better than the best accuracy
                
                    torch.save({'state_dict': model.state_dict(), 'args': args}, os.path.join(args.save, 'model.pth')) # Save the model weights
                    
                    best_acc = val_acc # Update the best accuracy to the current accuracy
                
                    # Add the info about the training
                logger.info(
                    "Epoch {:04d} | Time {:.3f} ({:.3f}) | NFE-F {:.1f} | NFE-B {:.1f} | "
                    "Train Acc {:.4f} | Test Acc {:.4f}".format(
                        itr // batches_per_epoch, batch_time_meter.val, batch_time_meter.avg, f_nfe_meter.avg,
                        b_nfe_meter.avg, train_acc, val_acc
                    )
                ) 
